{
  "hash": "a929a34de3eb3942a74ffb53eb467a87",
  "result": {
    "markdown": "---\ntitle: \"Accessing iNaturalist Data Using Python & Global Biodiversity Information Facility Data\"\ndescription: A tutuorial for using data from the Global Biodiversity Information Facilitiy (GBIF).\n\neditor: visual\nauthor:\n  - name: Kiran Favre\n    url: https://kiranfavre.github.io\n    affiliation: Master of Environmental Data Science\n    affiliation-url: https://ucsb-meds.github.io/\ndate: 12-02-2022\ncitation: \n  url: https://kiranfavre.github.io/posts/2022-12-02-python-inaturalist/ \ncategories: [Python, API]\nformat:\n  html:\n    code-fold: false\n    code-summary: \"Show code\"\nimage: pic.JPG\n---\n\n## Introduction\n\nThis repository is for our tutorial for using data from the [Global Biodiversity Information Facilitiy (GBIF)](https://www.gbif.org/). In collaboration with classmates Jillian Allison and Erica Bishop, we will be using an occurrence dataset about [iNaturalist Research Grade Observations](https://www.gbif.org/dataset/50c9509d-22c7-4a22-a47d-8c48425ef4a7). This blog will include an installation guide to get started using GBIF in a Python environment. This project was completed in a Jupyter Notebook.\n\nThe [GitHub repository](https://github.com/erica-bishop/eds220-finalproject) includes a Jupyter Notebook with the tutorial for EDS 220 Working With Environmental Data at UC Santa Barbara (Fall 2021 quarter).\n\n## Purpose\n\nWe are creating this notebook to:\n\n-   Explain the contents of iNaturalist data: what data is collected and what is the associated metadata?\n\n-   Demonstrate how to download this data for analysis.\n\n-   Show programmers some examples of visualizing and working with data from iNaturalist using Python.\n\n## Dataset Description\n\niNaturalist is a platform and social network for citizen scientists and biologists to upload photos of observed species along with the location and time collected. This dataset is a collection of iNaturalist research grade observations. Research grade observations are defined by having a photo, date, and coordinate provided and the community agrees upon the identification. iNaturalist users can identify the species in the photo based on previous users' uploads and community input.\n\nThis dataset was created and hosted by iNaturalist, an initiative by the California Academy of Sciences and National Geographic Society. It is also hosted on GBIF. GBIF, according to its website, \"is an international network and data infrastructure funded by the world's governments and aimed at providing anyone, anywhere, open access to data about all types of life on Earth.\" The standardized data in GBIF allows anyone in the world to access high quality ecological data.\n\nThe iNaturalist dataset's temporal span is from 1768 to present. Older data is based on historical records. The iNaturalist app was created in 2008, and people with iPhones have uploaded their own data via the app in recent years. iNaturalist data covers the entire globe.\n\nSome issues with data quality are highlighted by tags on the download report. Some of these issues include matching taxon to the correct identification, matching incorrect countries and coordinates, or multimedia date invalidities.\n\n## Installation Guide\n\nYou will need to make an account with GBIF to download data from their database.\n\nYou will also need to to install the package `pygif` to use the API for this data base. To install the package you can use the following commands in Python:\n\n`pip install pygbif`\n\n## Dataset Input/Output\n\nThere are a few different ways that we can access iNaturalist data. iNaturalist does manage an export feature on their website, but they note that large exports slow down their infrastructure. Their top recommendation for exporting data is to use GBIF. The file format used to store the data is a tab-delimited CSV.\n\nTo access data from GBIF you first need to set up an account. You can use your GitHub account to set this up. After you've created an account, you have two options for downloading data, the GBIF API or a file download.\n\n### How to use the API\n\nThe GBIF API is relatively easy to use. The prerequisite `pygbif` package for importing data into a python environment is already installed in the Python 3 kernel on Taylor. The API includes several different modules that you can use to search and query data. The examples below show how to use the `species` module or the `occurrences` module to get iNaturalist data on Adelie penguins.\n\nThere are many arguments you can use to query data from the API, and data is returned as a dictionary. Checkout the [pygbif 0.6.1 documentation](https://pygbif.readthedocs.io/en/latest/index.html) for more query examples.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pygbif #package to interface with GBIF API - this is preloaded on the Python3 kernel on taylor\nfrom pygbif import species #can call specific modules for searching\nfrom pygbif import occurrences as occ #easier to rename this for shorter coding in the use cases below\nadeliae_dict = species.name_lookup(institution_code=\"iNaturalist\", q='Pygoscelis adeliae') #using the species lookup\n```\n:::\n\n\n### How to dowload files from GBIF\n\nFor easily importing data you're interested in, you may want to download a TSV file from GBIF.\n\n### Reading in data to your environment\n\n1. Import necessary packages\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd # PANDAS FOR CSV DOWNLOAD\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom zipfile import ZipFile\n```\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}